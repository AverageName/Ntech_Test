{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled6.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1p1LL8h1cInQ7skZGZ53LT7t0OLPCYDE-","authorship_tag":"ABX9TyNjKMv/LQR1/1areN78kC1S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aaa54c85e62c43f78d7be5be7ccd6b77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a9855bce6c854d59a6bb67eb457ce321","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5bf3282bd9e64f1fbb46500b82153744","IPY_MODEL_93e3eb1192d2470b84b236aea8b0a2a1"]}},"a9855bce6c854d59a6bb67eb457ce321":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5bf3282bd9e64f1fbb46500b82153744":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bbf34d2937cd42f9afd4d8c4902c3d04","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":21388428,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":21388428,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_808c96dfd20047a88288ed2e618a6589"}},"93e3eb1192d2470b84b236aea8b0a2a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7607c03c5da6499d943dad9d493dc1ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 20.4M/20.4M [00:02&lt;00:00, 7.89MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b22cbd0fe4ec4f4eb6de69ee2584e04e"}},"bbf34d2937cd42f9afd4d8c4902c3d04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"808c96dfd20047a88288ed2e618a6589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7607c03c5da6499d943dad9d493dc1ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b22cbd0fe4ec4f4eb6de69ee2584e04e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"7NK6iicOqdl2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600355181055,"user_tz":-180,"elapsed":597,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}}},"source":["import torch\n","import albumentations as A\n","from torch.utils.data.dataset import Dataset\n","from torch.utils.data.dataloader import DataLoader\n","import os\n","from glob import glob\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torchvision\n","import torch.optim as optim\n","import math\n","#torch.manual_seed(69)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0fYBMV8qwAC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"status":"ok","timestamp":1600357198751,"user_tz":-180,"elapsed":224122,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}},"outputId":"ef857f22-4d52-42fa-d24c-c56c05aea7eb"},"source":["!cd /content/drive/My\\ Drive/internship_data/male/ && sh ../../script.sh"],"execution_count":23,"outputs":[{"output_type":"stream","text":["26\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n","hi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eZB2W_aWr4zf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600356947821,"user_tz":-180,"elapsed":1259,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}},"outputId":"a2911cd3-4df0-4851-d7ec-db481b27f4d6"},"source":["!cd /content/drive/My\\ Drive/internship_data/male && find . -maxdepth 1 -type f | wc -l"],"execution_count":22,"outputs":[{"output_type":"stream","text":["50001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MTCKIuMAEdob","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":257},"executionInfo":{"status":"ok","timestamp":1600355186213,"user_tz":-180,"elapsed":4563,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}},"outputId":"b1f85ac8-8a4e-438c-c4ed-e285a6ea17b6"},"source":["!pip install efficientnet_pytorch\n","from efficientnet_pytorch import EfficientNet"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting efficientnet_pytorch\n","  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16031 sha256=c6800cd76fe600a1bd8e80593ec949129ba66f562d53b133a8b452114370f33d\n","  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WIKXaES0rAkG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600355188248,"user_tz":-180,"elapsed":904,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}}},"source":["class FaceDataset(Dataset):\n","\n","    def __init__(self, root, folder_names, transforms=None):\n","\n","        self.root = root\n","        self.folder_names = folder_names\n","        self.transforms = transforms\n","\n","        self.males = glob(os.path.join(root, folder_names[0], '*.jpg'))\n","        self.females = glob(os.path.join(root, folder_names[1], '*.jpg'))\n","\n","        self.aug = transforms\n","\n","    def __len__(self):\n","        return len(self.males) + len(self.females)\n","\n","    def __getitem__(self, idx):\n","        if idx >= len(self.males):\n","            img_path = self.females[idx % len(self.males)]\n","            label = torch.tensor([0])\n","        else:\n","            img_path = self.males[idx]\n","            label = torch.tensor([1])\n","        \n","        img = np.array(Image.open(img_path))\n","        \n","        if self.transforms:\n","            img = self.aug(image=img)['image']\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","\n","        img = torch.tensor(img)\n","        return {\"img\": img, \"label\": label}"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrPaxVrbzGho","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600355189209,"user_tz":-180,"elapsed":494,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}}},"source":["def show_img(img):\n","    plt.figure(figsize=(18,15))\n","    # unnormalize\n","    img = torch.div(img, 2.0) + 0.5  \n","    npimg = img.numpy()\n","    npimg = np.clip(npimg, 0., 1.)\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEv-LfmPxMmI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600355310146,"user_tz":-180,"elapsed":120642,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}}},"source":["aug =  A.Compose({\n","        A.Resize(224, 224),\n","        A.HorizontalFlip(p=0.5),\n","        A.Rotate(limit=(-90, 90)),\n","        A.VerticalFlip(p=0.5),\n","        A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","        })\n","\n","dataset = FaceDataset('/content/drive/My Drive/internship_data/', ['male', 'female'], transforms=aug)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QzCc3DRA3Gxx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"error","timestamp":1600355323913,"user_tz":-180,"elapsed":653,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}},"outputId":"ddd42c47-8fcb-4119-e058-555eaec7a5de"},"source":["val_split = 0.2\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len(dataset) - math.floor(len(dataset) * val_split),\n","                                                                     math.floor(len(dataset) * val_split)])\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=64, num_workers=2)\n","val_dataloader = DataLoader(val_dataset, batch_size=32)"],"execution_count":7,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-597ffd6aeb63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len(dataset) - math.floor(len(dataset) * val_split),\n\u001b[1;32m      3\u001b[0m                                                                      math.floor(len(dataset) * val_split)])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m---> 96\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"]}]},{"cell_type":"code","metadata":{"id":"EIp8uTY91wt8","colab_type":"code","colab":{}},"source":["class GenderNet(nn.Module):\n","\n","    def __init__(self):\n","        super(GenderNet, self).__init__()\n","        # self.fe = torchvision.models.resnet34(pretrained=True)\n","        # head = nn.Linear(512, 2)\n","\n","        # self.fe.fc = head\n","\n","        self.fe = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2)\n","\n","    \n","    def forward(self, inputs):\n","        return self.fe(inputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hd3pD7t-332C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1599989806594,"user_tz":-180,"elapsed":846,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}},"outputId":"6f657945-ee8c-4553-d599-150529d3274c"},"source":["model = GenderNet()\n","inputs = torch.randn((1, 3, 224, 224))\n","out = model(inputs)\n","print(out.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n","torch.Size([1, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aBpsTPvLCa3L","colab_type":"code","colab":{}},"source":["def validate(model, val_loader):\n","\n","    correct = 0\n","    for idx, data in enumerate(val_loader):\n","\n","        images, labels = data['img'], data['label']\n","        images = images.cuda()\n","        labels = labels.cuda()\n","        labels = labels.squeeze()\n","\n","        predicts = torch.argmax(model(images), dim=1)\n","        correct += torch.sum((predicts == labels)).item()\n","\n","    return correct / (len(val_loader)*val_loader.batch_size)\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VvrUasoftOdp","colab_type":"code","colab":{}},"source":["\n","class BinaryFocalLoss(nn.Module):\n","    \"\"\"\n","    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n","    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n","        Focal_Loss= -1*alpha*(1-pt)*log(pt)\n","    :param num_class:\n","    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n","    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n","                    focus on hard misclassified example\n","    :param reduction: `none`|`mean`|`sum`\n","    :param **kwargs\n","        balance_index: (int) balance class index, should be specific when alpha is float\n","    \"\"\"\n","\n","    def __init__(self, alpha=[1.0, 1.0], gamma=2, ignore_index=None, reduction='mean'):\n","        super(BinaryFocalLoss, self).__init__()\n","        if alpha is None:\n","            alpha = [0.25, 0.75]\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.smooth = 1e-6\n","        self.ignore_index = ignore_index\n","        self.reduction = reduction\n","\n","        assert self.reduction in ['none', 'mean', 'sum']\n","\n","        if self.alpha is None:\n","            self.alpha = torch.ones(2)\n","        elif isinstance(self.alpha, (list, np.ndarray)):\n","            self.alpha = np.asarray(self.alpha)\n","            self.alpha = np.reshape(self.alpha, (2))\n","            assert self.alpha.shape[0] == 2, \\\n","                'the `alpha` shape is not match the number of class'\n","        elif isinstance(self.alpha, (float, int)):\n","            self.alpha = np.asarray([self.alpha, 1.0 - self.alpha], dtype=np.float).view(2)\n","\n","        else:\n","            raise TypeError('{} not supported'.format(type(self.alpha)))\n","\n","    def forward(self, output, target):\n","        #prob = torch.sigmoid(output)\n","        prob = torch.softmax(output, dim=1)\n","        prob = torch.clamp(prob, self.smooth, 1.0 - self.smooth)\n","\n","        pos_mask = (target == 1).float()\n","        neg_mask = (target == 0).float()\n","\n","        pos_loss = -self.alpha[0] * torch.pow(torch.sub(1.0, prob), self.gamma) * torch.log(prob) * pos_mask\n","        neg_loss = -self.alpha[1] * torch.pow(prob, self.gamma) * \\\n","                   torch.log(torch.sub(1.0, prob)) * neg_mask\n","\n","        neg_loss = neg_loss.sum()\n","        pos_loss = pos_loss.sum()\n","        num_pos = pos_mask.view(pos_mask.size(0), -1).sum()\n","        num_neg = neg_mask.view(neg_mask.size(0), -1).sum()\n","\n","        if num_pos == 0:\n","            loss = neg_loss\n","        else:\n","            loss = pos_loss / num_pos + neg_loss / num_neg\n","        return loss\n","\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, gamma=0, alpha=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n","        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n","        self.size_average = size_average\n","\n","    def forward(self, input, target):\n","        if input.dim()>2:\n","            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n","            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n","            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n","        target = target.view(-1,1)\n","\n","        logpt = F.log_softmax(input)\n","        logpt = logpt.gather(1,target)\n","        logpt = logpt.view(-1)\n","        pt = Variable(logpt.data.exp())\n","\n","        if self.alpha is not None:\n","            if self.alpha.type()!=input.data.type():\n","                self.alpha = self.alpha.type_as(input.data)\n","            at = self.alpha.gather(0,target.data.view(-1))\n","            logpt = logpt * Variable(at)\n","\n","        loss = -1 * (1-pt)**self.gamma * logpt\n","        if self.size_average: return loss.mean()\n","        else: return loss.sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3iU6kGU9xZrN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["aaa54c85e62c43f78d7be5be7ccd6b77","a9855bce6c854d59a6bb67eb457ce321","5bf3282bd9e64f1fbb46500b82153744","93e3eb1192d2470b84b236aea8b0a2a1","bbf34d2937cd42f9afd4d8c4902c3d04","808c96dfd20047a88288ed2e618a6589","7607c03c5da6499d943dad9d493dc1ff","b22cbd0fe4ec4f4eb6de69ee2584e04e"]},"executionInfo":{"status":"error","timestamp":1600102920775,"user_tz":-180,"elapsed":31848628,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}},"outputId":"6c7b65b1-dfb8-4c1a-8f3e-d323347d048d"},"source":["epochs = 15\n","model = GenderNet().cuda()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-6)\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss()\n","\n","best_acc = 0.0\n","for epoch in range(epochs):\n","\n","    model.train()\n","    running_loss = 0.0\n","    for idx, data in enumerate(train_dataloader):\n","        \n","        optimizer.zero_grad()\n","\n","        images, labels = data['img'], data['label']\n","\n","        images = images.cuda()\n","        labels = labels.cuda()\n","\n","        # labels = labels.squeeze()\n","\n","        outputs = model(images)\n","        # print(outputs.shape)\n","        # print(labels.shape)\n","        #print(outputs, labels)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        if idx % 20 == 19:\n","            print(\"Epoch №{}, step №{}, curr_loss: {}\".format(epoch + 1, idx + 1, running_loss / 20))\n","            running_loss = 0.0\n","    \n","    acc = validate(model, val_dataloader)\n","    print(\"Epoch №{}, val_acc: {}\".format(epoch + 1, acc))\n","    if acc > best_acc:\n","        best_acc = acc\n","        torch.save(model.state_dict(), '/content/drive/My Drive/best_checkp_gender_effnet-b0_focal.pth')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aaa54c85e62c43f78d7be5be7ccd6b77","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=21388428.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Loaded pretrained weights for efficientnet-b0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch №1, step №20, curr_loss: 0.6154579281806946\n","Epoch №1, step №40, curr_loss: 0.44793352037668227\n","Epoch №1, step №60, curr_loss: 0.3792500920593739\n","Epoch №1, step №80, curr_loss: 0.2966942861676216\n","Epoch №1, step №100, curr_loss: 0.2354627251625061\n","Epoch №1, step №120, curr_loss: 0.24992112666368485\n","Epoch №1, step №140, curr_loss: 0.21161431297659875\n","Epoch №1, step №160, curr_loss: 0.19069068506360054\n","Epoch №1, step №180, curr_loss: 0.1753121353685856\n","Epoch №1, step №200, curr_loss: 0.1730998620390892\n","Epoch №1, step №220, curr_loss: 0.1661858160048723\n","Epoch №1, step №240, curr_loss: 0.17039354629814624\n","Epoch №1, step №260, curr_loss: 0.13271207679063082\n","Epoch №1, step №280, curr_loss: 0.1566002953797579\n","Epoch №1, step №300, curr_loss: 0.17463073264807463\n","Epoch №1, step №320, curr_loss: 0.14586239960044622\n","Epoch №1, step №340, curr_loss: 0.1470921490341425\n","Epoch №1, step №360, curr_loss: 0.14367498084902763\n","Epoch №1, step №380, curr_loss: 0.1024130905047059\n","Epoch №1, step №400, curr_loss: 0.11956390663981438\n","Epoch №1, step №420, curr_loss: 0.1289027240127325\n","Epoch №1, step №440, curr_loss: 0.13541560973972083\n","Epoch №1, step №460, curr_loss: 0.15239964202046394\n","Epoch №1, step №480, curr_loss: 0.11313344314694404\n","Epoch №1, step №500, curr_loss: 0.11561600491404533\n","Epoch №1, step №520, curr_loss: 0.11604823172092438\n","Epoch №1, step №540, curr_loss: 0.12528351712971925\n","Epoch №1, step №560, curr_loss: 0.11996556129306554\n","Epoch №1, step №580, curr_loss: 0.11325650662183762\n","Epoch №1, step №600, curr_loss: 0.11020101439207793\n","Epoch №1, step №620, curr_loss: 0.10104999765753746\n","Epoch №1, step №640, curr_loss: 0.1269818913191557\n","Epoch №1, step №660, curr_loss: 0.11725500039756298\n","Epoch №1, step №680, curr_loss: 0.11577289048582315\n","Epoch №1, step №700, curr_loss: 0.10679712574928998\n","Epoch №1, step №720, curr_loss: 0.12793970853090286\n","Epoch №1, step №740, curr_loss: 0.10699961632490158\n","Epoch №1, step №760, curr_loss: 0.10472190640866756\n","Epoch №1, step №780, curr_loss: 0.09425704022869467\n","Epoch №1, step №800, curr_loss: 0.11089063938707114\n","Epoch №1, step №820, curr_loss: 0.1178649440407753\n","Epoch №1, step №840, curr_loss: 0.10793314939364791\n","Epoch №1, step №860, curr_loss: 0.10416078232228757\n","Epoch №1, step №880, curr_loss: 0.10207008179277181\n","Epoch №1, step №900, curr_loss: 0.09043306624516845\n","Epoch №1, step №920, curr_loss: 0.09215100519359112\n","Epoch №1, step №940, curr_loss: 0.08589129187166691\n","Epoch №1, step №960, curr_loss: 0.09610980860888958\n","Epoch №1, step №980, curr_loss: 0.09727013166993856\n","Epoch №1, step №1000, curr_loss: 0.1088628564029932\n","Epoch №1, step №1020, curr_loss: 0.11440598126500845\n","Epoch №1, step №1040, curr_loss: 0.11714386772364378\n","Epoch №1, step №1060, curr_loss: 0.10039069894701243\n","Epoch №1, step №1080, curr_loss: 0.08527907337993383\n","Epoch №1, step №1100, curr_loss: 0.08373366836458444\n","Epoch №1, step №1120, curr_loss: 0.09484925847500562\n","Epoch №1, step №1140, curr_loss: 0.08318086597137153\n","Epoch №1, step №1160, curr_loss: 0.10185448830015957\n","Epoch №1, step №1180, curr_loss: 0.09270991161465644\n","Epoch №1, step №1200, curr_loss: 0.11248885486274958\n","Epoch №1, step №1220, curr_loss: 0.09347039293497801\n","Epoch №1, step №1240, curr_loss: 0.08711061757057906\n"],"name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-9177a6c625a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch №{}, val_acc: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-98c434ce47c7>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-190823040156>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected"]}]},{"cell_type":"code","metadata":{"id":"msgZlySA5S0v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"ok","timestamp":1599954389792,"user_tz":-180,"elapsed":772,"user":{"displayName":"Daniil Pakhomov","photoUrl":"","userId":"17967021429473049474"}},"outputId":"640e74cf-01cf-438e-eb3a-15abe1ba67a4"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Sep 12 23:46:29 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   76C    P0    33W /  70W |  15025MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I8T1PbdVtoXd","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}